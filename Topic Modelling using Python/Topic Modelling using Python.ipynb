{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f875f5ba-fb1b-46ea-a2f2-fa193ee3b991",
   "metadata": {},
   "source": [
    "Article: The summary of the article.\n",
    "\n",
    "Title: The title of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abc5ce1-21e2-480e-8065-99838e8c9d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article  \\\n",
      "0  Data analysis is the process of inspecting and...   \n",
      "1  The performance of a machine learning algorith...   \n",
      "2  You must have seen the news divided into categ...   \n",
      "3  When there are only two classes in a classific...   \n",
      "4  The Multinomial Naive Bayes is one of the vari...   \n",
      "\n",
      "                                               Title  \n",
      "0                  Best Books to Learn Data Analysis  \n",
      "1         Assumptions of Machine Learning Algorithms  \n",
      "2          News Classification with Machine Learning  \n",
      "3  Multiclass Classification Algorithms in Machin...  \n",
      "4        Multinomial Naive Bayes in Machine Learning  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohith\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohith\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mohith\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Mohith\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "data = pd.read_csv(r\"C:\\Users\\Mohith Kumar\\Desktop\\Git Hub Projects\\UnSupervised Learning\\Topic Modelling using Python\\articles.csv\", encoding = 'latin1')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770e3e10-8577-4665-a9d9-271b6bceccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize tokens\n",
    "    lemma = WordNetLemmatizer()\n",
    "    tokens = [lemma.lemmatize(word) for word in tokens]\n",
    "    # Join tokens to form preprocessed text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "data['Article'] = data['Article'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2138bb67-2467-4c48-a744-27e3b356ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(data['Article'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f494f64-5855-4564-8ac6-98980ace8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(x)\n",
    "\n",
    "topic_modelling = lda.transform(x)\n",
    "\n",
    "topic_labels = np.argmax(topic_modelling, axis=1)\n",
    "data['topic_labels'] = topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3194dd07-9a85-40ea-82b0-32cb4bac7804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Title</th>\n",
       "      <th>topic_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data analysis is the process of inspecting and...</td>\n",
       "      <td>Best Books to Learn Data Analysis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The performance of a machine learning algorith...</td>\n",
       "      <td>Assumptions of Machine Learning Algorithms</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You must have seen the news divided into categ...</td>\n",
       "      <td>News Classification with Machine Learning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When there are only two classes in a classific...</td>\n",
       "      <td>Multiclass Classification Algorithms in Machin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Multinomial Naive Bayes is one of the vari...</td>\n",
       "      <td>Multinomial Naive Bayes in Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  Data analysis is the process of inspecting and...   \n",
       "1  The performance of a machine learning algorith...   \n",
       "2  You must have seen the news divided into categ...   \n",
       "3  When there are only two classes in a classific...   \n",
       "4  The Multinomial Naive Bayes is one of the vari...   \n",
       "\n",
       "                                               Title  topic_labels  \n",
       "0                  Best Books to Learn Data Analysis             3  \n",
       "1         Assumptions of Machine Learning Algorithms             4  \n",
       "2          News Classification with Machine Learning             1  \n",
       "3  Multiclass Classification Algorithms in Machin...             1  \n",
       "4        Multinomial Naive Bayes in Machine Learning             3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facccc9c-f264-4abf-973b-8844ade80367",
   "metadata": {},
   "source": [
    "Topic Modelling is a Natural Language Processing technique to uncover hidden topics from text documents. It helps identify topics of the text documents to find relationships between the content of a text document and the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafe202-bacf-4c8c-afbc-8da24d7497a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
